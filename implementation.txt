Noted
General Description
Noted is a downloadable macOS desktop app that pairs a lightweight on-screen mini-client—ideal for voice commands and keyboard shortcuts—with a full-featured main window where the heavy lifting happens. Designed for students, hobbyists, and entrepreneurs, it acts as a multimodal “second brain”: the app reads what’s on your screen, listens to your voice in real time, and responds instantly through a GPT-4o–powered assistant. This context awareness enables rapid Q&A, comprehension checks, and spaced-repetition drills for students, while hobbyists and founders can just as easily summon code explanations, textbook walk-throughs, or project research without breaking flow. By remembering relevant web context and minimizing task-switching overhead, Noted turns any work session into a more focused, cognitively efficient learning experience.
Core features

Context-aware assistant: Noted can read what’s on your screen and, when you permit, listen to your voice so every question you ask is instantly grounded in the right material.
Real-time voice responses: Speak a query and hear a clear answer almost before you finish the sentence—no typing required.
Mini overlay & hotkeys: A small, draggable widget plus global shortcuts let you call up summaries, definitions, or code fixes without breaking focus.
Context-linked notes & folders: Jot something down and the app automatically ties that note to the page, PDF, or repo you were viewing.
Automatic flashcards & voice drills: Your daily notes become spaced-repetition cards and quick verbal quizzes to keep key facts fresh.
Presentation and writing coach: Practice a talk or drop in a draft, and Noted flags awkward phrasing or missing logic so you can tighten things up on the spot.
Technical Description
Noted utilizes various AI functionalities, with its MCP server at its core with the AI voice Assistant. While the messages can be delivered through text, the users have the option to hear it through voice.  This would depend on the type of environment they are in and their personal preference. For example, for someone highly knowledgable and experimental in technology, they would be more open to use the two-way voice functionalities, while people who are more novel to voice functionalities,  may use the mini-client more to see the text or just the one-way audio when they hear it because they may still be awkward with this new technology. Within this web app, users are able to open multiple tabs for fuller flexibility; however, they will only be able to use one voice AI assistant.
Layout
The app has a controller on the left, in which users are able to navigate through the folders and notes just like google drive. First, users must first create a project or a root folder. This can be named an actual project name liked Noted or a class name like Physics 3. In there, there are the main folders like “Design” or “Chapter 1: Motion” which may contain subfolders or notes. A note is essentially very similar to a google doc but just our own version. Here, the user may add manual folders or notes, while they can also design it by using their voice through MCP functionalities. The ‘library’ holds all the material that the user may submit including pdfs like textbooks or a paper. They may also access the “workflows, ” which summarizes a time period in which the user had worked with all the info. For example, if I worked 1 PM- 4PM for the first for my project called Physics 3, that’d be my first 3 hour workflow. Now after this session if I were to click this, it would summarize what I did during that workflow and also have all the history and logs of what tools were called and what addition “library” materials I’ve added specific to that workflow, as I don’t want to cog up the whole memory space to be more accurate in efficient when we perform RAG. However material added in the controller, the user may permit if it’s “global” or not, which would mean all workflows would contain this file. The library section in the controller is where you would be able to control which resources to use when first starting a work session. For example, a biology textbook would always be used, while a specific paper wouldn’t be for one class. There’s also a Tools section in which the user is able to integrate external APIs like Google and Notion.  They may also define shortcuts here as well, in which the user is able to make functions like sending an email or fetching content from Notion. 
MCP Server
The core of our app is defined the by MCP server which is run with the Voice AI Assistant. Essentially, users will be able to think of tooling function that they want to implement themselves for their workflow, which they can add in the “Tools” tab; however, as of now, we are targeting a specific group of people who want to learn as a student, hobbyist, or entrepreneur. So I will also implement functionalities designated specifically for learners that will comprise of the functions above.  The right question to ask is “How can I enable tooling functionalities easily for my users who don’t have technical experience?” By creating sets of functions that users can use as a student, I will be able to gain knowledge myself and how to use this application.  

For this app we are using Supabase, 